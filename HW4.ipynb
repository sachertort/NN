{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7on9zlvDqbXL",
        "msnJwZQkcIYq"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание №4\n",
        "Рома Казаков"
      ],
      "metadata": {
        "id": "e34Yp0WMbcAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем датасет и необходимые библиотеки."
      ],
      "metadata": {
        "id": "QQICnGuxbmh_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_xZydvOVAJn",
        "outputId": "4304c0f5-8a9b-4aa2-ffcb-39d2007fe848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
            "To: /content/apps.csv\n",
            "100% 134k/134k [00:00<00:00, 51.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\n",
            "To: /content/reviews.csv\n",
            "100% 7.17M/7.17M [00:00<00:00, 49.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
        "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCoUI-J7Zxgn",
        "outputId": "b4ed2ea7-02ef-40fa-de4b-93dbc29d57cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 35.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 37.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 33.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from transformers import Trainer, TrainingArguments, BertModel, BertForSequenceClassification, BertTokenizer, TextClassificationPipeline\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "vgpnA5RGWgof"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "itcs0NGnTAd7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Данные"
      ],
      "metadata": {
        "id": "7on9zlvDqbXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"reviews.csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bKXYy-Y8WG7S",
        "outputId": "48863cd5-7d20-408a-c8e9-fe2a45bd483b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                userName                                          userImage  \\\n",
              "0          Andrew Thomas  https://lh3.googleusercontent.com/a-/AOh14GiHd...   \n",
              "1           Craig Haines  https://lh3.googleusercontent.com/-hoe0kwSJgPQ...   \n",
              "2          steven adkins  https://lh3.googleusercontent.com/a-/AOh14GiXw...   \n",
              "3       Lars Panzerbjørn  https://lh3.googleusercontent.com/a-/AOh14Gg-h...   \n",
              "4          Scott Prewitt  https://lh3.googleusercontent.com/-K-X1-YsVd6U...   \n",
              "...                  ...                                                ...   \n",
              "15741          Tammy Kay  https://lh3.googleusercontent.com/a-/AOh14GhYP...   \n",
              "15742          Ysm Johan  https://lh3.googleusercontent.com/a-/AOh14Ggmd...   \n",
              "15743      casey dearden  https://lh3.googleusercontent.com/a-/AOh14Gg2U...   \n",
              "15744     Jerry G Tamate  https://lh3.googleusercontent.com/a-/AOh14GiTP...   \n",
              "15745  Ahmed elsalamouni  https://lh3.googleusercontent.com/-9QSxVUhCoDI...   \n",
              "\n",
              "                                                 content  score  \\\n",
              "0      Update: After getting a response from the deve...      1   \n",
              "1      Used it for a fair amount of time without any ...      1   \n",
              "2      Your app sucks now!!!!! Used to be good but no...      1   \n",
              "3      It seems OK, but very basic. Recurring tasks n...      1   \n",
              "4      Absolutely worthless. This app runs a prohibit...      1   \n",
              "...                                                  ...    ...   \n",
              "15741  I believe that this is by far the best app wit...      5   \n",
              "15742                       It sometimes crashes a lot!!      5   \n",
              "15743                         Works well for what I need      5   \n",
              "15744                                           Love it.      5   \n",
              "15745  Really amazing and helped me sooo much just i ...      5   \n",
              "\n",
              "       thumbsUpCount reviewCreatedVersion                   at  \\\n",
              "0                 21             4.17.0.3  2020-04-05 22:25:57   \n",
              "1                 11             4.17.0.3  2020-04-04 13:40:01   \n",
              "2                 17             4.17.0.3  2020-04-01 16:18:13   \n",
              "3                192             4.17.0.2  2020-03-12 08:17:34   \n",
              "4                 42             4.17.0.2  2020-03-14 17:41:01   \n",
              "...              ...                  ...                  ...   \n",
              "15741              0                  NaN  2018-02-17 06:09:03   \n",
              "15742              0                4.3.7  2018-02-15 10:45:22   \n",
              "15743              0                4.3.7  2018-02-09 18:40:37   \n",
              "15744              0                  NaN  2018-02-06 12:36:17   \n",
              "15745              6                4.3.7  2018-02-04 22:57:09   \n",
              "\n",
              "                                            replyContent            repliedAt  \\\n",
              "0      According to our TOS, and the term you have ag...  2020-04-05 15:10:24   \n",
              "1      It sounds like you logged in with a different ...  2020-04-05 15:11:35   \n",
              "2      This sounds odd! We are not aware of any issue...  2020-04-02 16:05:56   \n",
              "3      We do offer this option as part of the Advance...  2020-03-15 06:20:13   \n",
              "4      We're sorry you feel this way! 90% of the app ...  2020-03-15 23:45:51   \n",
              "...                                                  ...                  ...   \n",
              "15741                                                NaN                  NaN   \n",
              "15742                                                NaN                  NaN   \n",
              "15743                                                NaN                  NaN   \n",
              "15744                                                NaN                  NaN   \n",
              "15745                                                NaN                  NaN   \n",
              "\n",
              "           sortOrder              appId  \n",
              "0      most_relevant          com.anydo  \n",
              "1      most_relevant          com.anydo  \n",
              "2      most_relevant          com.anydo  \n",
              "3      most_relevant          com.anydo  \n",
              "4      most_relevant          com.anydo  \n",
              "...              ...                ...  \n",
              "15741         newest  com.appxy.planner  \n",
              "15742         newest  com.appxy.planner  \n",
              "15743         newest  com.appxy.planner  \n",
              "15744         newest  com.appxy.planner  \n",
              "15745         newest  com.appxy.planner  \n",
              "\n",
              "[15746 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c78256a-ad6b-4961-84c7-a16cdd4a672e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Thomas</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
              "      <td>Update: After getting a response from the deve...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-05 22:25:57</td>\n",
              "      <td>According to our TOS, and the term you have ag...</td>\n",
              "      <td>2020-04-05 15:10:24</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Craig Haines</td>\n",
              "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
              "      <td>Used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-04 13:40:01</td>\n",
              "      <td>It sounds like you logged in with a different ...</td>\n",
              "      <td>2020-04-05 15:11:35</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steven adkins</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
              "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-01 16:18:13</td>\n",
              "      <td>This sounds odd! We are not aware of any issue...</td>\n",
              "      <td>2020-04-02 16:05:56</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lars Panzerbjørn</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
              "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-12 08:17:34</td>\n",
              "      <td>We do offer this option as part of the Advance...</td>\n",
              "      <td>2020-03-15 06:20:13</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scott Prewitt</td>\n",
              "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
              "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-14 17:41:01</td>\n",
              "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
              "      <td>2020-03-15 23:45:51</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15741</th>\n",
              "      <td>Tammy Kay</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GhYP...</td>\n",
              "      <td>I believe that this is by far the best app wit...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-02-17 06:09:03</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>newest</td>\n",
              "      <td>com.appxy.planner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15742</th>\n",
              "      <td>Ysm Johan</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Ggmd...</td>\n",
              "      <td>It sometimes crashes a lot!!</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4.3.7</td>\n",
              "      <td>2018-02-15 10:45:22</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>newest</td>\n",
              "      <td>com.appxy.planner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15743</th>\n",
              "      <td>casey dearden</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg2U...</td>\n",
              "      <td>Works well for what I need</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4.3.7</td>\n",
              "      <td>2018-02-09 18:40:37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>newest</td>\n",
              "      <td>com.appxy.planner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15744</th>\n",
              "      <td>Jerry G Tamate</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiTP...</td>\n",
              "      <td>Love it.</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-02-06 12:36:17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>newest</td>\n",
              "      <td>com.appxy.planner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15745</th>\n",
              "      <td>Ahmed elsalamouni</td>\n",
              "      <td>https://lh3.googleusercontent.com/-9QSxVUhCoDI...</td>\n",
              "      <td>Really amazing and helped me sooo much just i ...</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>4.3.7</td>\n",
              "      <td>2018-02-04 22:57:09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>newest</td>\n",
              "      <td>com.appxy.planner</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15746 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c78256a-ad6b-4961-84c7-a16cdd4a672e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c78256a-ad6b-4961-84c7-a16cdd4a672e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c78256a-ad6b-4961-84c7-a16cdd4a672e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df.score)\n",
        "plt.xlabel('review score');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "G3tgahpqWm1i",
        "outputId": "90aeb22d-2ff6-4838-bca3-d6e86ea7a9d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрев на данные и поняв, что они неравномерны, объединяем классы 1 и 2 в \"негативные\" отзывы, а 4 и 5 — в \"позитивные\". 3, соответственно, — нейтральные."
      ],
      "metadata": {
        "id": "xZGqcRWmbvy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else: \n",
        "    return 2\n",
        "\n",
        "df['sentiment'] = df.score.apply(to_sentiment)\n",
        "\n",
        "class_names = ['negative', 'neutral', 'positive']\n",
        "\n",
        "ax = sns.countplot(df.sentiment)\n",
        "plt.xlabel('review sentiment')\n",
        "ax.set_xticklabels(class_names);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "gvV1-eO7WurP",
        "outputId": "ade9bdce-8154-44db-be77-21972463d69a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кажется, новое распределение намного лучше."
      ],
      "metadata": {
        "id": "6QlxIrPNcEBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Предобработка"
      ],
      "metadata": {
        "id": "msnJwZQkcIYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я использовал модель `prajjwal1/bert-tiny` — не самая качественная, но зато компактная и быстрая."
      ],
      "metadata": {
        "id": "dAnUNK6IcNOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'prajjwal1/bert-tiny'\n",
        "N_CLASSES = len(class_names)"
      ],
      "metadata": {
        "id": "5SUiiv2PXCQA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получаем обучающий, валидационный и тестовый сеты данных."
      ],
      "metadata": {
        "id": "v4M6VIcEch7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(df.content.to_list(), \n",
        "                                                                    df.sentiment.to_list(), \n",
        "                                                                    test_size=0.1)\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(train_texts,\n",
        "                                                                      train_labels,\n",
        "                                                                      test_size=0.1)"
      ],
      "metadata": {
        "id": "_41JAdKLEFxs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализируем токенизатор."
      ],
      "metadata": {
        "id": "1uLb-RcLcnIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "cr57VqQaQ2hc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "q62MFi1FEWBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e3f067-bf18-475a-c084-da25accecb43"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаём кастомный датасет на основе наших данных, который можно будет использовать в `Trainer`."
      ],
      "metadata": {
        "id": "tKWYPGjbcrgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = GPDataset(train_encodings, train_labels)\n",
        "val_dataset = GPDataset(val_encodings, val_labels)\n",
        "test_dataset = GPDataset(test_encodings, test_labels)"
      ],
      "metadata": {
        "id": "pcGV2YwxD6hs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Эксперименты"
      ],
      "metadata": {
        "id": "dH8ajtP-rhPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для подсчёта метрик во время обучения моделей."
      ],
      "metadata": {
        "id": "-If3yfWqfvN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "id": "qMo6JYb4d-qv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 1"
      ],
      "metadata": {
        "id": "ybm8aoc1gPKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Единые для всех моделей гиперпараметры. Размер батча подбирал вручную."
      ],
      "metadata": {
        "id": "gIWUO1j0f0Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results', \n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,     \n",
        "    num_train_epochs=7,              \n",
        "    per_device_train_batch_size=32,  \n",
        "    per_device_eval_batch_size=64,                   \n",
        "    weight_decay=0.01,               \n",
        "    logging_steps=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRhJOeQIaJom",
        "outputId": "4b6730b0-56a8-41c7-f2c3-c10149f88a6b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нам понадобится `CrossEntropyLoss` для вывода наших моделей."
      ],
      "metadata": {
        "id": "_K-xJK93gFjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fct = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "8ohtqJlIu8iW"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Класс из тетрадки с семинара. Сюда добавлена `CrossEntropyLoss` для корректной передачи в `Trainer`."
      ],
      "metadata": {
        "id": "4qfcPtCLgS64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super().__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask, labels, token_type_ids):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      return_dict=False)\n",
        "    output = self.drop(pooled_output)\n",
        "    return (loss_fct(self.out(output), labels), self.out(output))"
      ],
      "metadata": {
        "id": "g1dC14TGcyM1"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = SentimentClassifier(N_CLASSES).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRqVnLT4es6a",
        "outputId": "039784a8-5a23-4f29-c619-208e97e48dbb"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModel were initialized from the model checkpoint at prajjwal1/bert-tiny.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_1 = Trainer(\n",
        "    model=model_1,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics = compute_metrics\n",
        ")\n",
        "\n",
        "trainer_1.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AfpepaqasI4x",
        "outputId": "13aab8eb-9dc5-49e5-d875-d0f50a9a6a47"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 12753\n",
            "  Num Epochs = 7\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2793\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2793' max='2793' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2793/2793 02:06, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.016400</td>\n",
              "      <td>1.002846</td>\n",
              "      <td>0.535873</td>\n",
              "      <td>0.506233</td>\n",
              "      <td>0.518102</td>\n",
              "      <td>0.535873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.125900</td>\n",
              "      <td>0.893745</td>\n",
              "      <td>0.574603</td>\n",
              "      <td>0.510488</td>\n",
              "      <td>0.565632</td>\n",
              "      <td>0.574603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.851600</td>\n",
              "      <td>0.841387</td>\n",
              "      <td>0.608254</td>\n",
              "      <td>0.583409</td>\n",
              "      <td>0.590501</td>\n",
              "      <td>0.608254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.708000</td>\n",
              "      <td>0.823469</td>\n",
              "      <td>0.612063</td>\n",
              "      <td>0.591889</td>\n",
              "      <td>0.600159</td>\n",
              "      <td>0.612063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.538900</td>\n",
              "      <td>0.811405</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.605300</td>\n",
              "      <td>0.607416</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.839500</td>\n",
              "      <td>0.807554</td>\n",
              "      <td>0.617778</td>\n",
              "      <td>0.600797</td>\n",
              "      <td>0.604951</td>\n",
              "      <td>0.617778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.557300</td>\n",
              "      <td>0.805421</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.604014</td>\n",
              "      <td>0.605674</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2793, training_loss=0.8961893808359405, metrics={'train_runtime': 126.5844, 'train_samples_per_second': 705.229, 'train_steps_per_second': 22.064, 'total_flos': 0.0, 'train_loss': 0.8961893808359405, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нужно сказать, что метрики на этой базовой вариации оказались наиболее высокими."
      ],
      "metadata": {
        "id": "3Pzz6qg6gqjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_1.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "3bllRO86a9e7",
        "outputId": "cae23032-aa58-483b-bee8-1595e3e5bb55"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1418\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23/23 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 7.0,\n",
              " 'test_accuracy': 0.6375176304654443,\n",
              " 'test_f1': 0.6208350138433825,\n",
              " 'test_loss': 0.7860105037689209,\n",
              " 'test_precision': 0.6268108578112584,\n",
              " 'test_recall': 0.6375176304654443,\n",
              " 'test_runtime': 0.547,\n",
              " 'test_samples_per_second': 2592.405,\n",
              " 'test_steps_per_second': 42.049}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 2"
      ],
      "metadata": {
        "id": "72IktsgyhRYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавлен вектор `[CLS]` токена из `last_hidden_state`."
      ],
      "metadata": {
        "id": "rz9bymoEhT5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifier_CLS(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super().__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size*2, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask, labels, token_type_ids):\n",
        "    last_hidden_state, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      return_dict=False)\n",
        "    output = self.drop(torch.cat((pooled_output, last_hidden_state[:, 0, :]), 1))\n",
        "    return (loss_fct(self.out(output), labels), self.out(output))"
      ],
      "metadata": {
        "id": "k_40S3O9Ax04"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = SentimentClassifier_CLS(N_CLASSES).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwBSWYlXLuxn",
        "outputId": "a9baa4ad-dffb-453b-caaf-29b03dec7268"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModel were initialized from the model checkpoint at prajjwal1/bert-tiny.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_2 = Trainer(\n",
        "    model=model_2,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics = compute_metrics\n",
        ")\n",
        "\n",
        "trainer_2.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iCF4YgIXLSjp",
        "outputId": "19a15d6c-e876-401e-9268-1dd4cb7c106b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 12753\n",
            "  Num Epochs = 7\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2793\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2793' max='2793' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2793/2793 02:08, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.939500</td>\n",
              "      <td>0.938005</td>\n",
              "      <td>0.559365</td>\n",
              "      <td>0.550802</td>\n",
              "      <td>0.549472</td>\n",
              "      <td>0.559365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.884300</td>\n",
              "      <td>0.848725</td>\n",
              "      <td>0.599365</td>\n",
              "      <td>0.585884</td>\n",
              "      <td>0.592440</td>\n",
              "      <td>0.599365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.817063</td>\n",
              "      <td>0.621587</td>\n",
              "      <td>0.610165</td>\n",
              "      <td>0.611822</td>\n",
              "      <td>0.621587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.671000</td>\n",
              "      <td>0.802935</td>\n",
              "      <td>0.631111</td>\n",
              "      <td>0.622523</td>\n",
              "      <td>0.622552</td>\n",
              "      <td>0.631111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.580600</td>\n",
              "      <td>0.795247</td>\n",
              "      <td>0.636825</td>\n",
              "      <td>0.635097</td>\n",
              "      <td>0.635855</td>\n",
              "      <td>0.636825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.852900</td>\n",
              "      <td>0.788981</td>\n",
              "      <td>0.637460</td>\n",
              "      <td>0.629977</td>\n",
              "      <td>0.630971</td>\n",
              "      <td>0.637460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.583600</td>\n",
              "      <td>0.787374</td>\n",
              "      <td>0.641270</td>\n",
              "      <td>0.636002</td>\n",
              "      <td>0.635396</td>\n",
              "      <td>0.641270</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2793, training_loss=0.8818499888201746, metrics={'train_runtime': 128.1698, 'train_samples_per_second': 696.506, 'train_steps_per_second': 21.791, 'total_flos': 0.0, 'train_loss': 0.8818499888201746, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_2.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "XKeorQfrbGDb",
        "outputId": "9e9317b4-edc2-43ee-ac0f-f4459ac7a381"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1418\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='46' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23/23 00:16]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 7.0,\n",
              " 'test_accuracy': 0.6558533145275035,\n",
              " 'test_f1': 0.6505330737681808,\n",
              " 'test_loss': 0.7588615417480469,\n",
              " 'test_precision': 0.649029800783844,\n",
              " 'test_recall': 0.6558533145275035,\n",
              " 'test_runtime': 0.6317,\n",
              " 'test_samples_per_second': 2244.791,\n",
              " 'test_steps_per_second': 36.411}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 3"
      ],
      "metadata": {
        "id": "vyMU5D6Vh2OC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь была добавлена готовая модель для классификации последовательности — `BertForSequenceClassification`."
      ],
      "metadata": {
        "id": "SOhzeJVbh50r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME, \n",
        "                                                      num_labels=N_CLASSES).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewQG2eOSLV0j",
        "outputId": "02d6182c-a8fa-4ccb-8a6f-dbc403b619fa"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_3 = Trainer(\n",
        "    model=model_3,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics = compute_metrics\n",
        ")\n",
        "\n",
        "trainer_3.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zquj3UrcavYC",
        "outputId": "c3b2410b-a692-4e8b-ee74-8e6f5eae135a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 12753\n",
            "  Num Epochs = 7\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2793\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2793' max='2793' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2793/2793 02:07, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.961900</td>\n",
              "      <td>0.971715</td>\n",
              "      <td>0.560635</td>\n",
              "      <td>0.544557</td>\n",
              "      <td>0.545497</td>\n",
              "      <td>0.560635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.940700</td>\n",
              "      <td>0.885343</td>\n",
              "      <td>0.579683</td>\n",
              "      <td>0.543956</td>\n",
              "      <td>0.569948</td>\n",
              "      <td>0.579683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.878700</td>\n",
              "      <td>0.837163</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.606490</td>\n",
              "      <td>0.608709</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.703200</td>\n",
              "      <td>0.822266</td>\n",
              "      <td>0.623492</td>\n",
              "      <td>0.611669</td>\n",
              "      <td>0.616337</td>\n",
              "      <td>0.623492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.610300</td>\n",
              "      <td>0.808589</td>\n",
              "      <td>0.627302</td>\n",
              "      <td>0.618024</td>\n",
              "      <td>0.618857</td>\n",
              "      <td>0.627302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.838300</td>\n",
              "      <td>0.807319</td>\n",
              "      <td>0.628571</td>\n",
              "      <td>0.616747</td>\n",
              "      <td>0.621960</td>\n",
              "      <td>0.628571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.804133</td>\n",
              "      <td>0.633016</td>\n",
              "      <td>0.621724</td>\n",
              "      <td>0.625448</td>\n",
              "      <td>0.633016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Configuration saved in ./results/checkpoint-1000/config.json\n",
            "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Configuration saved in ./results/checkpoint-1500/config.json\n",
            "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Configuration saved in ./results/checkpoint-2000/config.json\n",
            "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Configuration saved in ./results/checkpoint-2500/config.json\n",
            "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2793, training_loss=0.8673458646114608, metrics={'train_runtime': 127.2637, 'train_samples_per_second': 701.465, 'train_steps_per_second': 21.947, 'total_flos': 107248563237816.0, 'train_loss': 0.8673458646114608, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_3.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "hwhxSxytbNWt",
        "outputId": "ccc62f95-663e-4523-9867-fcbfd1f2f52e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1418\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23/23 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 7.0,\n",
              " 'test_accuracy': 0.6318758815232722,\n",
              " 'test_f1': 0.6187137801397601,\n",
              " 'test_loss': 0.7884083986282349,\n",
              " 'test_precision': 0.6226682352031228,\n",
              " 'test_recall': 0.6318758815232722,\n",
              " 'test_runtime': 0.5488,\n",
              " 'test_samples_per_second': 2583.814,\n",
              " 'test_steps_per_second': 41.91}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 4*"
      ],
      "metadata": {
        "id": "hFn7DeSei3l6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я попытался взять `[CLS]` токены для нескольких слоев, чтобы сделать предсказание класса."
      ],
      "metadata": {
        "id": "qvtP8wDJi9gQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifier_CLS_hidden(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super().__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask, labels, token_type_ids):\n",
        "    last_hidden_state, pooled_output, hidden_states = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      return_dict=False,\n",
        "      output_hidden_states=True)\n",
        "\n",
        "    output = self.drop(hidden_states[1][:, 0, :])\n",
        "    return (loss_fct(self.out(output), labels), self.out(output))"
      ],
      "metadata": {
        "id": "O7tNjKOPNMFi"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = SentimentClassifier_CLS_hidden(N_CLASSES).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQKx4-SqOheQ",
        "outputId": "79d7308a-f4a8-4040-f6c0-7c4027c00b55"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3cf34679007e9fe5d0acd644dcc1f4b26bec5cbc9612364f6da7262aed4ef7a4.a5a11219cf90aae61ff30e1658ccf2cb4aa84d6b6e947336556f887c9828dc6d\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/prajjwal1/bert-tiny/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1ee037c9e1a220d5c814779ffe697080d1e6f5b1602e16cf6061aaae41a082c5.038e1aed90492a59d2283f9c44c9fe3ee2380495ff1e7fefb3f1f04af3b685b5\n",
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModel were initialized from the model checkpoint at prajjwal1/bert-tiny.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_4 = Trainer(\n",
        "    model=model_4,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics = compute_metrics\n",
        ")\n",
        "\n",
        "trainer_4.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JS8oRQRnOcQk",
        "outputId": "73123b73-d27e-48e6-a964-b5b126b299c6"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 12753\n",
            "  Num Epochs = 7\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2793\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2793' max='2793' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2793/2793 01:34, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.032600</td>\n",
              "      <td>1.065281</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.417329</td>\n",
              "      <td>0.454736</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.215500</td>\n",
              "      <td>0.993380</td>\n",
              "      <td>0.540952</td>\n",
              "      <td>0.493756</td>\n",
              "      <td>0.525149</td>\n",
              "      <td>0.540952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.915700</td>\n",
              "      <td>0.915381</td>\n",
              "      <td>0.584762</td>\n",
              "      <td>0.552423</td>\n",
              "      <td>0.572929</td>\n",
              "      <td>0.584762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.883300</td>\n",
              "      <td>0.871244</td>\n",
              "      <td>0.607619</td>\n",
              "      <td>0.587905</td>\n",
              "      <td>0.596171</td>\n",
              "      <td>0.607619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.789000</td>\n",
              "      <td>0.849492</td>\n",
              "      <td>0.620317</td>\n",
              "      <td>0.609621</td>\n",
              "      <td>0.608049</td>\n",
              "      <td>0.620317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.853500</td>\n",
              "      <td>0.838907</td>\n",
              "      <td>0.626032</td>\n",
              "      <td>0.611613</td>\n",
              "      <td>0.612896</td>\n",
              "      <td>0.626032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.632000</td>\n",
              "      <td>0.835860</td>\n",
              "      <td>0.626032</td>\n",
              "      <td>0.612814</td>\n",
              "      <td>0.612760</td>\n",
              "      <td>0.626032</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1575\n",
            "  Batch size = 64\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2793, training_loss=0.9804578406000667, metrics={'train_runtime': 94.6606, 'train_samples_per_second': 943.064, 'train_steps_per_second': 29.505, 'total_flos': 0.0, 'train_loss': 0.9804578406000667, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_4.evaluate(eval_dataset=test_dataset, metric_key_prefix=\"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "HFM5x1rqbQ6k",
        "outputId": "185be5a5-a6a9-45b7-9852-355263a79a8f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1418\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='46' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23/23 00:21]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 7.0,\n",
              " 'test_accuracy': 0.61212976022567,\n",
              " 'test_f1': 0.5949031167765135,\n",
              " 'test_loss': 0.8227170705795288,\n",
              " 'test_precision': 0.596202826191629,\n",
              " 'test_recall': 0.61212976022567,\n",
              " 'test_runtime': 0.6168,\n",
              " 'test_samples_per_second': 2298.894,\n",
              " 'test_steps_per_second': 37.288}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Моделью с наивысшей F1-мерой оказалась система из второго задания, где сконкатенированы `pooler output` и вектор `[CLS]` токена."
      ],
      "metadata": {
        "id": "dBhahS4ykWQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 5"
      ],
      "metadata": {
        "id": "WrzYdmUCk9X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tcp = TextClassificationPipeline(model=model_3, tokenizer=tokenizer)\n",
        "model_3.to('cpu')"
      ],
      "metadata": {
        "id": "rnAjrMlOviH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEGATIBE\n",
        "neg = '''Worse with every update and the worst customer support I've ever \n",
        "come across. Very frustrating to use, as updates eliminate normal/common \n",
        "sense features and add useless ones. I am now unable to do the most basic \n",
        "thing one would do in a chat app - check my contacts. First, they eliminated \n",
        "the contacts menu and made you click on \"new chat\" to do this; but now, that's \n",
        "gone too. You have to look for people specifically, using the search function. \n",
        "Just one example among many...'''\n",
        "print(tcp([neg]))\n",
        "\n",
        "# NEUTRAL\n",
        "neutral = '''I wish they add the option to add longer stories like a minute \n",
        "long. What's wrong with having the option to add a 30 second story and a one \n",
        "minute story . Or the option to add a gif to your profile picture. Overall it's \n",
        "good app but it could be better.'''\n",
        "print(tcp([neutral]))\n",
        "\n",
        "# POSITIVE\n",
        "pos = '''Best game so far played - ads are very less - it can be addictive at \n",
        "some point of time - best in game carreer and monster trucks to play with - easy\n",
        "to handle - difficult to master - no not at all a pay to win game - and for me \n",
        "never ever lagged on my device - truly can't believe that game is launched in \n",
        "November yet there are no bugs - developers are really very hard working and \n",
        "had developed the best game for people to play '''\n",
        "print(tcp([pos]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGTifuBePDaM",
        "outputId": "eef481c3-d41c-4bbc-82ac-f3f77306067d"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'LABEL_0', 'score': 0.6285752058029175}]\n",
            "[{'label': 'LABEL_1', 'score': 0.5131343603134155}]\n",
            "[{'label': 'LABEL_2', 'score': 0.803077757358551}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На несложных примерах всё получилось."
      ],
      "metadata": {
        "id": "89RMB7MwwlT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "it9WYQF1qOeL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}